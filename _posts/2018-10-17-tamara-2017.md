---
layout: post
title: Automated Scalable Bayesian Inference via Hilbert Coresets
---

Tamara Broderick, assistant professor at MIT gave a talk in Oct 17 2018 at Yale. I'm going to spend a little bit of time on making a summary on her talk. 
Let's take a look at the following equation:

$$
\pi(\theta) = \frac{1}{Z} \exp(\mathcal{L}(\theta))\pi_0(\theta)
$$
where:

$$
\mathcal{L}_n(\theta) = \log p(y_n| \theta) , \mathcal{L}(\theta) = \sum_{n=1}^{N} \mathcal{L}_n(\theta) , Z = \int \exp(\mathcal{L}(\theta)) \pi_0(\theta) \text{d}\theta
$$

In Bayesian theory, $\pi(\theta)$ is known as posterior probability, $\pi_0(\theta)$ is our prior on parameters, and $\exp(\mathcal{L}(\theta))$ is our likelihood.  
Recently John Lafferty in Data Mining and Machine Learning class mentioned that alsmot 25% of the machine learning papers are about bayesian inference.
It's really cool and really simple! Our model missing true parameters and we need to impute them after observing data. 
But computing $Z$ is really expensive and that is the main intuition behind Bayesian coreset which is a small weighted subset of the original dataset which is able to approximate it in a more efficient way.
So our aim here is to find a set of non-negative weights $w = (w_n)_{n=1}^N$ such that:

$$
\mathcal{L}(w,\theta) = \sum_{n=1}^N w_n \mathcal{L}_n (\theta) \\
s.t., |\mathcal{L}(w,\theta)- \mathcal{L}(\theta)\leq| \epsilon |\mathcal{L}(\theta)|, \forall \theta \in \Theta
$$

Huggins et alproposed weights for samples as follow:

$$
\sigma_n = \text{sup} |\frac{\mathcal{L}_n(\theta)}{\mathcal{L}(\theta) |
$$

and then suggested to take $M$ independant draws with probability proportional to $\sigma_n$:

$$
\sigma = \sum_{n=1}^{N} \sigma_n, (M_1,..,M_N) \sim \text{Mult}(M, (\frac{\sigma_n}{\sigma})_{n=1}^{N})), W_n = \frac{\sigma}{\sigma_n} \frac{M_n}{M}
$$

There is not really that much fundamental you need to know to figure it out that $\mathcal{E}[W_n]=1$ and then 

```
@article{Campbell:2017,
  title={Automated Scalable Bayesian Inference via Hilbert Coresets},
  author={Campbell, Trevor and Broderick, Tamara},
  journal={arXiv preprint arXiv:1710.05053},
  year={2017}
}
```
